{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ3LZoi4to94"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# ─── 1. Layer‐builders ───────────────────────────────────────────────\n",
        "\n",
        "def build_sLSTM_layers(units):\n",
        "    return {\n",
        "        'input_gate':    tf.keras.layers.Dense(units),\n",
        "        'forget_gate':   tf.keras.layers.Dense(units),\n",
        "        'output_gate':   tf.keras.layers.Dense(units),\n",
        "        'input_transf':  tf.keras.layers.Dense(units),\n",
        "    }\n",
        "\n",
        "def build_mLSTM_layers(units):\n",
        "    return {\n",
        "        'key_transf':    tf.keras.layers.Dense(units),\n",
        "        'value_transf':  tf.keras.layers.Dense(units),\n",
        "        'query_transf':  tf.keras.layers.Dense(units),\n",
        "        'input_gate':    tf.keras.layers.Dense(units),\n",
        "        'forget_gate':   tf.keras.layers.Dense(units),\n",
        "        'output_gate':   tf.keras.layers.Dense(units),\n",
        "    }\n",
        "\n",
        "# ─── 2. Step‐functions ──────────────────────────────────────────────\n",
        "\n",
        "def sLSTM_step(x, h_prev, c_prev, layers):\n",
        "    i_t = tf.nn.softplus(layers['input_gate'](x))  # more stable than exp\n",
        "    f_t = tf.sigmoid(layers['forget_gate'](x))\n",
        "    o_t = tf.sigmoid(layers['output_gate'](x))\n",
        "    z_t = tf.tanh(layers['input_transf'](x))\n",
        "\n",
        "    c_t = f_t * c_prev + i_t * z_t\n",
        "    h_t = o_t * tf.tanh(c_t)\n",
        "    return h_t, c_t\n",
        "\n",
        "def mLSTM_step(x, h_prev, C_prev, layers):\n",
        "    k = layers['key_transf'](x)\n",
        "    v = layers['value_transf'](x)\n",
        "    q = layers['query_transf'](x)\n",
        "\n",
        "    i_t = tf.nn.softplus(layers['input_gate'](x))  # more stable than exp\n",
        "    f_t = tf.sigmoid(layers['forget_gate'](x))\n",
        "    o_t = tf.sigmoid(layers['output_gate'](x))\n",
        "\n",
        "    v_e = tf.expand_dims(v, 2)     # (batch, d, 1)\n",
        "    k_e = tf.expand_dims(k, 1)     # (batch, 1, d)\n",
        "    delta_C = v_e @ k_e            # (batch, d, d)\n",
        "\n",
        "    C_t = f_t[:, None, None] * C_prev + i_t[:, None, None] * delta_C\n",
        "\n",
        "    q_e = tf.expand_dims(q, 2)     # (batch, d, 1)\n",
        "    h_t = tf.squeeze(C_t @ q_e, 2) # (batch, d)\n",
        "    h_t = o_t * h_t\n",
        "\n",
        "    return h_t, C_t\n",
        "\n",
        "# ─── 3. Model as a tf.keras.Model subclass ──────────────────────────\n",
        "\n",
        "class xLSTM(tf.keras.Model):\n",
        "    def __init__(self, hidden_dim, block_types):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.block_types = block_types\n",
        "        self.blocks = []\n",
        "\n",
        "        for bt in block_types:\n",
        "            if bt == 'sLSTM':\n",
        "                self.blocks.append(('s', build_sLSTM_layers(hidden_dim)))\n",
        "            else:\n",
        "                self.blocks.append(('m', build_mLSTM_layers(hidden_dim)))\n",
        "\n",
        "        self.output_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        batch = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "\n",
        "        # Initialize hidden and cell states\n",
        "        h = [tf.zeros((batch, self.hidden_dim)) for _ in self.blocks]\n",
        "        c = []\n",
        "        for kind, _ in self.blocks:\n",
        "            if kind == 's':\n",
        "                c.append(tf.zeros((batch, self.hidden_dim)))\n",
        "            else:\n",
        "                c.append(tf.zeros((batch, self.hidden_dim, self.hidden_dim)))\n",
        "\n",
        "        # TensorArray to collect outputs over time\n",
        "        ta = tf.TensorArray(tf.float32, size=seq_len)\n",
        "\n",
        "        for t in tf.range(seq_len):\n",
        "            x = inputs[:, t, :]\n",
        "            for i, (kind, layers) in enumerate(self.blocks):\n",
        "                if kind == 's':\n",
        "                    h[i], c[i] = sLSTM_step(x, h[i], c[i], layers)\n",
        "                else:\n",
        "                    h[i], c[i] = mLSTM_step(x, h[i], c[i], layers)\n",
        "                x = h[i]  # feed to next block\n",
        "\n",
        "            ta = ta.write(t, h[-1])  # only top layer's output\n",
        "\n",
        "        # Gather outputs and return final time step's top hidden state\n",
        "        outs = ta.stack()                    # (seq_len, batch, dim)\n",
        "        outs = tf.transpose(outs, [1, 0, 2]) # (batch, seq_len, dim)\n",
        "        final = outs[:, -1, :]               # (batch, dim)\n",
        "        return self.output_layer(final)      # (batch, 1)\n"
      ]
    }
  ]
}