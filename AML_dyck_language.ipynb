{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tjGyUa1ngt2N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Corrected xLSTM Implementation\n",
        "class xLSTMCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units, units, units]  # h, c, n, m\n",
        "        self.output_size = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "        # Proper weight initialization from paper\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(input_dim, 4 * self.units),\n",
        "            initializer='glorot_uniform',\n",
        "            name='kernel'\n",
        "        )\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, 4 * self.units),  # Fixed size to match all gates\n",
        "            initializer='orthogonal',\n",
        "            name='recurrent_kernel'\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(4 * self.units,),\n",
        "            initializer='zeros',\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev, n_prev, m_prev = states\n",
        "\n",
        "        # Compute all gates together\n",
        "        gates = tf.matmul(inputs, self.kernel) + tf.matmul(h_prev, self.recurrent_kernel) + self.bias\n",
        "\n",
        "        # Split into components following paper equations\n",
        "        z, i, f, o = tf.split(gates, num_or_size_splits=4, axis=1)\n",
        "\n",
        "        # Exponential gating with stabilization\n",
        "        i_t = tf.exp(i)  # Input gate (exp activation)\n",
        "        f_t = tf.exp(f)  # Forget gate (exp activation)\n",
        "\n",
        "        # Stabilization mechanism (Equation 15-17)\n",
        "        m_t = tf.maximum(tf.math.log(f_t) + m_prev, tf.math.log(i_t))\n",
        "        i_prime = tf.exp(tf.math.log(i_t) - m_t)\n",
        "        f_prime = tf.exp(tf.math.log(f_t) + m_prev - m_t)\n",
        "\n",
        "        # State updates (Equations 8-10)\n",
        "        n_t = f_prime * n_prev + i_prime\n",
        "        c_t = f_prime * c_prev + i_prime * tf.tanh(z)\n",
        "        h_t = tf.sigmoid(o) * (c_t / (n_t + 1e-8))  # Add epsilon for numerical stability\n",
        "\n",
        "        return h_t, [h_t, c_t, n_t, m_t]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced model builder\n",
        "def build_model(cell_type, units=32, input_dim=3):\n",
        "    inputs = tf.keras.Input(shape=(None, input_dim))\n",
        "\n",
        "    if cell_type == 'xLSTM':\n",
        "        cell = xLSTMCell(units)\n",
        "        x = tf.keras.layers.RNN(cell, return_sequences=False)(inputs)\n",
        "    elif cell_type == 'LSTM':\n",
        "        x = tf.keras.layers.LSTM(units, return_sequences=False)(inputs)\n",
        "    else:\n",
        "        x = tf.keras.layers.SimpleRNN(units, return_sequences=False)(inputs)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Enhanced training with proper regularization\n",
        "def train_and_evaluate(model, x_train, y_train, x_test, y_test, name):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.0),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    # Add early stopping\n",
        "    es = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_test, y_test),\n",
        "        epochs=20,\n",
        "        batch_size=32,\n",
        "        callbacks=[es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Get best validation accuracy\n",
        "    best_epoch = np.argmin(history.history['val_loss'])\n",
        "    best_acc = history.history['val_accuracy'][best_epoch]\n",
        "    print(f\"{name} Best Validation Accuracy: {best_acc:.4f}\")\n",
        "    return best_acc\n"
      ],
      "metadata": {
        "id": "0I_lRSeSwazI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate enhanced dataset\n",
        "    def generate_dyck(n_samples, max_len=20):\n",
        "        # Improved dataset generation with more challenging patterns\n",
        "        data = []\n",
        "        labels = []\n",
        "        for _ in range(n_samples):\n",
        "            depth = 0\n",
        "            s = []\n",
        "            valid = True\n",
        "            for _ in range(max_len):\n",
        "                if random.random() < 0.5:\n",
        "                    s.append('(')\n",
        "                    depth += 1\n",
        "                else:\n",
        "                    s.append(')')\n",
        "                    depth -= 1\n",
        "                    if depth < 0:\n",
        "                        valid = False\n",
        "            label = 1 if valid and depth == 0 else 0\n",
        "            data.append(''.join(s))\n",
        "            labels.append(label)\n",
        "        return data, labels\n",
        "\n",
        "    # Vectorizer with masking\n",
        "    def vectorize_data(sequences, vocab={'(': 0, ')': 1}, max_len=20):\n",
        "        vec = np.zeros((len(sequences), max_len, len(vocab)), dtype=np.float32)\n",
        "        for i, seq in enumerate(sequences):\n",
        "            for t, char in enumerate(seq[:max_len]):\n",
        "                if char in vocab:\n",
        "                    vec[i, t, vocab[char]] = 1.0\n",
        "        return vec\n",
        "\n",
        "    # Create enhanced dataset\n",
        "    train_seqs, train_labels = generate_dyck(5000, 20)\n",
        "    test_seqs, test_labels = generate_dyck(1000, 20)\n",
        "    x_train = vectorize_data(train_seqs)\n",
        "    x_test = vectorize_data(test_seqs)\n",
        "    y_train = np.array(train_labels)\n",
        "    y_test = np.array(test_labels)\n",
        "\n",
        "    # Compare models\n",
        "    results = {}\n",
        "    for model_type in ['xLSTM', 'LSTM', 'RNN']:\n",
        "        model = build_model(model_type, units=32, input_dim=2)  # Reduced input dim since we removed padding token\n",
        "        acc = train_and_evaluate(model, x_train, y_train, x_test, y_test, model_type)\n",
        "        results[model_type] = acc\n",
        "\n",
        "    print(\"\\nFinal Comparison:\")\n",
        "    for model, acc in results.items():\n",
        "        print(f\"{model}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0ersGxoQJu2",
        "outputId": "905589e7-349e-458f-d9f9-38abc6867b5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xLSTM Best Validation Accuracy: 0.9940\n",
            "LSTM Best Validation Accuracy: 0.9910\n",
            "RNN Best Validation Accuracy: 0.9840\n",
            "\n",
            "Final Comparison:\n",
            "xLSTM: 0.9940\n",
            "LSTM: 0.9910\n",
            "RNN: 0.9840\n"
          ]
        }
      ]
    }
  ]
}